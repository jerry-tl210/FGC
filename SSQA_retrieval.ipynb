{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence \n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import AdamW\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = pd.read_json(\"FGC_release_1.7.13/FGC_release_all_dev.json\")\n",
    "training_data = pd.read_json(\"FGC_release_1.7.13/FGC_release_all_train.json\")\n",
    "test_data = pd.read_json(\"FGC_release_1.7.13/FGC_release_all_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocessing(data, is_dev=False):\n",
    "    \n",
    "    # Save all the questions, potential supporting evidence and indices in three lists\n",
    "    textQ_to_be_tokenized = []\n",
    "    textA_to_be_tokenized = []\n",
    "    sp_index = []\n",
    "    \n",
    "    for dictionary in data['QUESTIONS']:\n",
    "        for element in dictionary:\n",
    "            textQ_to_be_tokenized.append(element['QTEXT_CN'])\n",
    "            sp_index.append(element['SHINT_'])\n",
    "    for dictionary in data['SENTS']:\n",
    "        current_text_sentence = []\n",
    "        for element in dictionary:\n",
    "            current_text_sentence.append(element['text'])\n",
    "        textA_to_be_tokenized.append(current_text_sentence)\n",
    "    \n",
    "    QandA_label = pd.DataFrame({'Question': textQ_to_be_tokenized,\n",
    "                                'Sentence_List': textA_to_be_tokenized,\n",
    "                                'SE_Index': sp_index,\n",
    "                                'Label': sp_index})\n",
    "    \n",
    "    QandA_label['Length'] = QandA_label['Sentence_List'].apply(lambda x: len(x))\n",
    "    QandA_label['SE_Index'] = QandA_label['SE_Index'].apply(lambda x: [0])\n",
    "    QandA_label['SE_Index'] = QandA_label['SE_Index'] * QandA_label['Length']\n",
    "    QandA_label['SE_Index'] = list(zip(QandA_label['SE_Index'], QandA_label['Label']))\n",
    "\n",
    "    # Extract label index\n",
    "    for row in QandA_label['SE_Index']:\n",
    "        for index in row[1]:\n",
    "            row[0][index] = 1\n",
    "        \n",
    "    indexed = [i[0] for i in list(QandA_label['SE_Index'])]\n",
    "    QandA_label['Label'] = indexed\n",
    "\n",
    "    Q_and_Sentence_all_Comb = pd.DataFrame({'Question':np.repeat(QandA_label['Question'].values, QandA_label['Sentence_List'].str.len()),\n",
    "                        'Sentence':np.concatenate(QandA_label['Sentence_List'].values)})\n",
    "    Q_and_Sentence_all_Comb['Label'] = QandA_label['Label'].sum()\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "            \n",
    "    # Put all question and sentence combination into a list \n",
    "    All_instances = []\n",
    "    for i in range(len(QandA_label)):\n",
    "        for sentence in QandA_label['Sentence_List'][i]:\n",
    "            question_token = tokenizer.tokenize(QandA_label['Question'][i])\n",
    "            sentence_token = tokenizer.tokenize(sentence)\n",
    "            instance = ['[CLS]'] + question_token + ['[SEP]'] + sentence_token + ['[SEP]']\n",
    "            if len(instance) > 512:\n",
    "                instance = instance[:512]\n",
    "            All_instances.append(instance)\n",
    "            \n",
    "    # Convert ids to segment_ids\n",
    "    segment_ids = []\n",
    "    for token in All_instances:\n",
    "        length_of_zeros = token.index('[SEP]') - token.index('[CLS]') + 1\n",
    "        length_of_ones = len(token) - length_of_zeros\n",
    "        zeros_and_ones = [0] * length_of_zeros + [1] * length_of_ones\n",
    "        segment_ids.append(zeros_and_ones)\n",
    "        \n",
    "    ids = []\n",
    "    for token in All_instances:\n",
    "        ids.append(tokenizer.convert_tokens_to_ids(token))\n",
    "        \n",
    "    mask_ids = []\n",
    "    for token in All_instances:\n",
    "        mask_ids.append([1] * len(token))\n",
    "        \n",
    "    labels = list(Q_and_Sentence_all_Comb['Label'])\n",
    "    labels = [[i] for i in labels]\n",
    "    \n",
    "    return All_instances, ids, segment_ids, mask_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 01:59:50.011849 140491409098560 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "I0703 01:59:54.834610 140491409098560 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "dev_instances, dev_ids, dev_seg_ids, dev_mask_ids, dev_labels = datapreprocessing(validation_data, True)\n",
    "train_instances, train_ids, train_seg_ids, train_mask_ids, train_labels = datapreprocessing(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ids, segment_ids, mask_ids, labels):\n",
    "        self.instances = []\n",
    "        for ids_i, segment_ids_i, mask_ids, label in zip(ids, segment_ids, mask_ids, labels):\n",
    "            self.instances.append({\"ids\": ids_i, \"segment_ids\": segment_ids_i, \n",
    "                                   \"mask_ids\": mask_ids, \"labels\": label})  \n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.instances[idx]\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentenceDataset(train_ids, train_seg_ids, train_mask_ids, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = SentenceDataset(dev_ids, dev_seg_ids, dev_mask_ids, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in batch], batch_first=True)\n",
    "    padded_ids = padded_ids.to(device)\n",
    "    \n",
    "    padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in batch], batch_first=True)\n",
    "    padded_segment_ids = padded_segment_ids.to(device)\n",
    "    \n",
    "    padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in batch], batch_first=True)\n",
    "    padded_mask_ids = padded_mask_ids.to(device)\n",
    "    \n",
    "    labels = torch.stack([torch.tensor(instance['labels']) for instance in batch])\n",
    "    labels = labels.to(device)\n",
    "    return {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(train_dataset, batch_size=8, shuffle = True, collate_fn = collate)\n",
    "#dataloader_dev = DataLoader(dev_dataset, collate_fn = collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preprocessing(data, dataset):\n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    for i in range(len(dataset.instances)):\n",
    "\n",
    "        instance = dataset.instances[i]\n",
    "        dictionary_lists.append(instance)\n",
    "\n",
    "        if i in len_array - 1:\n",
    "\n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGC_Network(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(FGC_Network, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # batch['ids'] = (batch_size, sent_len)\n",
    "        # batch['segment_ids'] = (batch_size, sent_len)\n",
    "        # batch['mask_ids'] = = (batch_size, sent_len)\n",
    "        # output = (batch_size, 1)\n",
    "        hidden_state, pooler_output = self.bert(batch['ids'], batch['mask_ids'], batch['segment_ids'])\n",
    "        linear_output = self.linear(pooler_output)\n",
    "        \n",
    "        return linear_output\n",
    "\n",
    "    def loss(self, batch):\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        output = self.forward(batch)\n",
    "        target = batch['labels'].float().to(device)\n",
    "        \n",
    "        return loss_fn(output, target)\n",
    "    \n",
    "    def _predict(self, batch):\n",
    "        \n",
    "        output = self.forward(batch)\n",
    "        scores = torch.sigmoid(output)\n",
    "        scores = scores.cpu().numpy()[:,0].tolist()\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def predict_fgc(self, batch, threshold=0.5):\n",
    "        \n",
    "        scores = self._predict(batch)\n",
    "\n",
    "        max_i = 0\n",
    "        max_score = 0\n",
    "        sp = []\n",
    "        \n",
    "        for i, score in enumerate(scores):\n",
    "\n",
    "            if score > max_score:\n",
    "                max_i = i\n",
    "                max_score = score\n",
    "            if score >= threshold:\n",
    "                sp.append(i)\n",
    "\n",
    "        if not sp:\n",
    "            sp.append(max_i)\n",
    "\n",
    "        return {'sp': sp, 'sp_scores': scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 02:00:14.653911 140491409098560 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0703 02:00:14.657922 140491409098560 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0703 02:00:15.517849 140491409098560 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FGC_Network(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = FGC_Network()\n",
    "network.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim(nn, num_epochs, lr):\n",
    "    param_optimizer = list(nn.bert.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    num_epochs = num_epochs\n",
    "    num_train_optimization_steps = len(dataloader_train) * num_epochs\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                     num_warmup_steps=int(\n",
    "                                                         num_train_optimization_steps * 0.1),\n",
    "                                                     num_training_steps=num_train_optimization_steps)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_sp(metrics, sp_gold, sp_pred):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "        \n",
    "    for p in sp_pred:\n",
    "        if p in sp_gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    for g in sp_gold:\n",
    "        if g not in sp_pred:\n",
    "            fn += 1\n",
    "            \n",
    "    precision = 1.0 * tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = 1.0 * tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n",
    "    em = 1.0 if fp + fn == 0 else 0.0\n",
    "    \n",
    "    metrics['sp_em'] += em\n",
    "    metrics['sp_f1'] += f1\n",
    "    metrics['sp_prec'] += precision\n",
    "    metrics['sp_recall'] += recall\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sp_fgc(sp_golds, sp_preds):\n",
    "    \n",
    "    metrics = {'sp_em': 0, 'sp_prec': 0, 'sp_recall': 0, 'sp_f1': 0}\n",
    "    \n",
    "    assert len(sp_golds) == len(sp_preds)\n",
    "    \n",
    "    for sp_gold, sp_pred in zip(sp_golds, sp_preds):\n",
    "        _update_sp(metrics, sp_gold, sp_pred)\n",
    "    \n",
    "    N = len(sp_golds)\n",
    "    for k in metrics.keys():\n",
    "        metrics[k] /= N\n",
    "        metrics[k] = round(metrics[k], 3)\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fgc_atype(atype_golds, atype_preds):\n",
    "    \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    \n",
    "    for gold, atype in zip(atype_golds, atype_preds):\n",
    "        if atype == gold:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    return pos/len(atypes_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(network, dev_batches, current_epoch, sp_golds, avg_loss):\n",
    "    \n",
    "    network.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sp_preds = []\n",
    "        \n",
    "        #atype_preds = []\n",
    "        for batch in tqdm(dev_batches):\n",
    "            \n",
    "            out_dct = network.predict_fgc(batch)\n",
    "            sp_preds.append(out_dct['sp'])\n",
    "            \n",
    "            #if 'atype' in out_dct:\n",
    "                #for type_i in out_dct['atype']:\n",
    "                    #assert type_i == out_dct['atype'][0]\n",
    "                #atype_preds.append(type_i)\n",
    "                \n",
    "  \n",
    "    metrics = eval_sp_fgc(sp_golds, sp_preds)\n",
    "    print('epoch %d eval_recall: %.3f eval_f1: %.3f loss: %.3f' % (\n",
    "            current_epoch, metrics['sp_recall'], metrics['sp_f1'], avg_loss))\n",
    "        \n",
    "    #torch.save(network.state_dict(), \"FGC_release_1.7.13/models_with_scheduler/model_epoch{0}_eval_em:{1:.3f}_precision:{2:.3f}_recall:{3:.3f}_f1:{4:.3f}_loss:{5:.3f}.m\".format(current_epoch, metrics['sp_em'], metrics['sp_prec'], metrics['sp_recall'], metrics['sp_f1'], avg_loss))\n",
    "    \n",
    "    return sp_preds, sp_golds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, num_epochs, lr):\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer, scheduler = optim(network, num_epochs, lr)\n",
    "    \n",
    "    sp_golds = validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    #atype_golds = validation_data['QUESTIONS'].apply(lambda x: x[0]['ATYPE_']).tolist()\n",
    "    \n",
    "    for current_epoch in range(num_epochs):\n",
    "        network.train()\n",
    "        running_loss = 0.0\n",
    "        dr = True\n",
    "        for batch in tqdm(dataloader_train):\n",
    "            optimizer.zero_grad()\n",
    "            current_output = network(batch)\n",
    "            current_target = batch['labels'].to(dtype=torch.float, device=device)\n",
    "            current_loss = loss_fn(current_output, current_target)\n",
    "\n",
    "            current_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(network.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += current_loss.item()\n",
    "            \n",
    "        learning_rate_scalar = scheduler.get_lr()[0]\n",
    "        print('lr = %f' % learning_rate_scalar)\n",
    "        avg_loss = running_loss/len(dataloader_train)\n",
    "        print('epoch %d train_loss: %.3f' % (current_epoch, avg_loss))\n",
    "        eval(network, dev_batches, current_epoch, sp_golds, avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2a53805bd946c5bf3541b295e8e353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000010\n",
      "epoch 0 train_loss: 0.213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e93fe6a68b4444f93b9726b421391bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.142, 'sp_prec': 0.592, 'sp_recall': 0.611, 'sp_f1': 0.543}\n",
      "epoch 0 eval_recall: 0.611 eval_f1: 0.543 loss: 0.213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5042101ea81246228c5ee50c3c0f7324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000020\n",
      "epoch 1 train_loss: 0.163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe0ea2c6ebb4569a4b674374c37b39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.15, 'sp_prec': 0.59, 'sp_recall': 0.63, 'sp_f1': 0.554}\n",
      "epoch 1 eval_recall: 0.630 eval_f1: 0.554 loss: 0.163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b15232cf7b4ea88fb5b77c9d80d2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000019\n",
      "epoch 2 train_loss: 0.135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102366f09ad14a8caf0499b374d4bd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.166, 'sp_prec': 0.619, 'sp_recall': 0.532, 'sp_f1': 0.522}\n",
      "epoch 2 eval_recall: 0.532 eval_f1: 0.522 loss: 0.135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bfab1ec5984ff28730bb0d0b578e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000018\n",
      "epoch 3 train_loss: 0.106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb88ec8b762b43d8b7fb9dd576b1675e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.186, 'sp_prec': 0.661, 'sp_recall': 0.532, 'sp_f1': 0.548}\n",
      "epoch 3 eval_recall: 0.532 eval_f1: 0.548 loss: 0.106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc3b4cb31dd4888b626ba71c51c6f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000017\n",
      "epoch 4 train_loss: 0.083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9a8ba3874442f28038024a6d96a20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.174, 'sp_prec': 0.627, 'sp_recall': 0.545, 'sp_f1': 0.538}\n",
      "epoch 4 eval_recall: 0.545 eval_f1: 0.538 loss: 0.083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4e810f2092490d9857210c5c1f52f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000016\n",
      "epoch 5 train_loss: 0.062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d82e8927484b38a7341e007d385782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.182, 'sp_prec': 0.59, 'sp_recall': 0.614, 'sp_f1': 0.547}\n",
      "epoch 5 eval_recall: 0.614 eval_f1: 0.547 loss: 0.062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3598dfce18474337918545bc2065b54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000014\n",
      "epoch 6 train_loss: 0.050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3ed96801bd4030a5ffd2688a00890b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.154, 'sp_prec': 0.565, 'sp_recall': 0.617, 'sp_f1': 0.538}\n",
      "epoch 6 eval_recall: 0.617 eval_f1: 0.538 loss: 0.050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9027e33631914473a26087dd486cc8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000013\n",
      "epoch 7 train_loss: 0.039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285429c3c8364bf295bd8d493d6fc794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.146, 'sp_prec': 0.535, 'sp_recall': 0.627, 'sp_f1': 0.517}\n",
      "epoch 7 eval_recall: 0.627 eval_f1: 0.517 loss: 0.039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1082bf78dd49d59baa3545334913ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(network, 20, 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 05:30:48.277780 140491409098560 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0703 05:30:48.282982 140491409098560 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0703 05:30:49.519857 140491409098560 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_network = FGC_Network()\n",
    "trained_network.load_state_dict(torch.load('FGC_release_1.7.13/models_with_scheduler/model_epoch19_eval_em:0.154_precision:0.599_recall:0.609_f1:0.547_loss:0.001.m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99e10c0f836465d9bd45acf004ff8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.985, 'sp_prec': 0.986, 'sp_recall': 0.988, 'sp_f1': 0.987}\n",
      "epoch 0 eval_recall: 0.988 eval_f1: 0.987 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "sp_golds = training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "batches = eval_preprocessing(training_data, train_dataset)\n",
    "\n",
    "trained_network.to(\"cuda\")\n",
    "train_pred, train_obs = eval(trained_network, batches, 0, sp_golds, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance = training_data.copy()\n",
    "training_data_with_performance['train_pred'] = train_pred\n",
    "training_data_with_performance['train_obs'] = train_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DID</th>\n",
       "      <th>QUESTIONS</th>\n",
       "      <th>DTEXT</th>\n",
       "      <th>DTEXT_CN</th>\n",
       "      <th>SENTS</th>\n",
       "      <th>train_pred</th>\n",
       "      <th>train_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>D006</td>\n",
       "      <td>[{'QID': 'D006Q02', 'QTYPE': '申論', 'ATYPE_': '...</td>\n",
       "      <td>阿拉伯之春（阿拉伯語：الثورات العربية‎）是西方主流媒體所稱的阿拉伯世界的一次...</td>\n",
       "      <td>阿拉伯之春（阿拉伯语：الثورات العربية‎）是西方主流媒体所称的阿拉伯世界的一次...</td>\n",
       "      <td>[{'text': '阿拉伯之春（阿拉伯语：الثورات العربية‎）是西方主流媒体...</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>D032</td>\n",
       "      <td>[{'QID': 'D032Q10', 'QTYPE': '進階題', 'ATYPE_': ...</td>\n",
       "      <td>北美自由貿易協定（英語：North American Free Trade Agreemen...</td>\n",
       "      <td>北美自由贸易协定（英语：North American Free Trade Agreemen...</td>\n",
       "      <td>[{'text': '北美自由贸易协定（英语：North American Free Tra...</td>\n",
       "      <td>[11]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>D048</td>\n",
       "      <td>[{'QID': 'D048Q09', 'QTYPE': '申論', 'ATYPE_': '...</td>\n",
       "      <td>聊天機器人並非最近幾年出現的新應用，麻省理工學院（MIT）人工智慧實驗室早在1966年即研發...</td>\n",
       "      <td>聊天机器人并非最近几年出现的新应用，麻省理工学院（MIT）人工智慧实验室早在1966年即研发...</td>\n",
       "      <td>[{'text': '聊天机器人并非最近几年出现的新应用，', 'start': 0, 'e...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>D086</td>\n",
       "      <td>[{'QID': 'D086Q03', 'QTYPE': '申論', 'ATYPE_': '...</td>\n",
       "      <td>在自然界中，能源可以採取幾種不同的形式存在：熱，電，輻射，化學能等。許多這些形式可以很容易轉...</td>\n",
       "      <td>在自然界中，能源可以采取几种不同的形式存在：热，电，辐射，化学能等。许多这些形式可以很容易转...</td>\n",
       "      <td>[{'text': '在自然界中，', 'start': 0, 'end': 6, 'IE'...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>D094</td>\n",
       "      <td>[{'QID': 'D094Q01', 'QTYPE': '申論', 'ATYPE_': '...</td>\n",
       "      <td>財團法人伊甸社會福利基金會（英語：Eden Social Welfare Foundatio...</td>\n",
       "      <td>财团法人伊甸社会福利基金会（英语：Eden Social Welfare Foundatio...</td>\n",
       "      <td>[{'text': '财团法人伊甸社会福利基金会（英语：Eden Social Welfar...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>D107</td>\n",
       "      <td>[{'QID': 'D107Q07', 'QTYPE': '進階題', 'ATYPE_': ...</td>\n",
       "      <td>根據政府公權力介入的程度，健康照護體系一般可以區分為以下三種不同的體系。\\n社會保險制（台灣...</td>\n",
       "      <td>根据政府公权力介入的程度，健康照护体系一般可以区分为以下三种不同的体系。\\n社会保险制（台湾...</td>\n",
       "      <td>[{'text': '根据政府公权力介入的程度，', 'start': 0, 'end': ...</td>\n",
       "      <td>[12, 25]</td>\n",
       "      <td>[25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>371</td>\n",
       "      <td>D107</td>\n",
       "      <td>[{'QID': 'D107Q08', 'QTYPE': '進階題', 'ATYPE_': ...</td>\n",
       "      <td>根據政府公權力介入的程度，健康照護體系一般可以區分為以下三種不同的體系。\\n社會保險制（台灣...</td>\n",
       "      <td>根据政府公权力介入的程度，健康照护体系一般可以区分为以下三种不同的体系。\\n社会保险制（台湾...</td>\n",
       "      <td>[{'text': '根据政府公权力介入的程度，', 'start': 0, 'end': ...</td>\n",
       "      <td>[12, 25]</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>D116</td>\n",
       "      <td>[{'QID': 'D116Q09', 'QTYPE': '進階題', 'ATYPE_': ...</td>\n",
       "      <td>在流行病學家及醫學研究者繼續探討癌症的相關生活因素的同時，美國醫學會所出版的著名醫學雜誌也於...</td>\n",
       "      <td>在流行病学家及医学研究者继续探讨癌症的相关生活因素的同时，美国医学会所出版的著名医学杂志也于...</td>\n",
       "      <td>[{'text': '在流行病学家及医学研究者继续探讨癌症的相关生活因素的同时，', 'st...</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>D182</td>\n",
       "      <td>[{'QID': 'D182Q07', 'QTYPE': '基礎題', 'ATYPE_': ...</td>\n",
       "      <td>國慶焰火在9月24號晚間試放3分鐘，為確保施放安全、順利，屏東縣政府表示24號當天屏東河濱公...</td>\n",
       "      <td>国庆焰火在9月24号晚间试放3分钟，为确保施放安全、顺利，屏东县政府表示24号当天屏东河滨公...</td>\n",
       "      <td>[{'text': '国庆焰火在9月24号晚间试放3分钟，', 'start': 0, 'e...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>D245</td>\n",
       "      <td>[{'QID': 'D245Q05', 'QTYPE': '申論', 'ATYPE_': '...</td>\n",
       "      <td>到了15世紀，聖伯多祿大殿結構日益變舊，亞維農教廷遷回羅馬後，萊昂·巴蒂斯塔·阿伯提和貝爾納...</td>\n",
       "      <td>到了15世纪，圣伯多禄大殿结构日益变旧，亚维农教廷迁回罗马后，莱昂·巴蒂斯塔·阿伯提和贝尔纳...</td>\n",
       "      <td>[{'text': '到了15世纪，', 'start': 0, 'end': 7, 'IE...</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>D272</td>\n",
       "      <td>[{'QID': 'D272Q09', 'QTYPE': '進階題', 'ATYPE_': ...</td>\n",
       "      <td>我們現在有好幾種筆可以使用：表現中國書法的特點，用毛筆；適應現代光面的紙張，用鋼筆；為了可以...</td>\n",
       "      <td>我们现在有好几种笔可以使用：表现中国书法的特点，用毛笔；适应现代光面的纸张，用钢笔；为了可以...</td>\n",
       "      <td>[{'text': '我们现在有好几种笔可以使用：表现中国书法的特点，', 'start':...</td>\n",
       "      <td>[62]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>731</td>\n",
       "      <td>D288</td>\n",
       "      <td>[{'QID': 'D288Q12', 'QTYPE': '申論', 'ATYPE_': '...</td>\n",
       "      <td>如果你到埃及旅行，沿著尼羅河前進，你將會看到一座座巍峨的金字塔，矗立在一望無際沙漠中。在蔚藍...</td>\n",
       "      <td>如果你到埃及旅行，沿著尼罗河前进，你将会看到一座座巍峨的金字塔，矗立在一望无际沙漠中。在蔚蓝...</td>\n",
       "      <td>[{'text': '如果你到埃及旅行，', 'start': 0, 'end': 9, '...</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>874</td>\n",
       "      <td>D322</td>\n",
       "      <td>[{'QID': 'D322Q07', 'QTYPE': '申論', 'ATYPE_': '...</td>\n",
       "      <td>國內腸病毒輕症疫情持續上升，另新增1例腸病毒71型併發重症病例。疾病管制署再次呼籲，腸病毒傳...</td>\n",
       "      <td>国内肠病毒轻症疫情持续上升，另新增1例肠病毒71型并发重症病例。疾病管制署再次呼吁，肠病毒传...</td>\n",
       "      <td>[{'text': '国内肠病毒轻症疫情持续上升，', 'start': 0, 'end':...</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DID                                          QUESTIONS  \\\n",
       "20   D006  [{'QID': 'D006Q02', 'QTYPE': '申論', 'ATYPE_': '...   \n",
       "70   D032  [{'QID': 'D032Q10', 'QTYPE': '進階題', 'ATYPE_': ...   \n",
       "156  D048  [{'QID': 'D048Q09', 'QTYPE': '申論', 'ATYPE_': '...   \n",
       "284  D086  [{'QID': 'D086Q03', 'QTYPE': '申論', 'ATYPE_': '...   \n",
       "324  D094  [{'QID': 'D094Q01', 'QTYPE': '申論', 'ATYPE_': '...   \n",
       "370  D107  [{'QID': 'D107Q07', 'QTYPE': '進階題', 'ATYPE_': ...   \n",
       "371  D107  [{'QID': 'D107Q08', 'QTYPE': '進階題', 'ATYPE_': ...   \n",
       "395  D116  [{'QID': 'D116Q09', 'QTYPE': '進階題', 'ATYPE_': ...   \n",
       "449  D182  [{'QID': 'D182Q07', 'QTYPE': '基礎題', 'ATYPE_': ...   \n",
       "502  D245  [{'QID': 'D245Q05', 'QTYPE': '申論', 'ATYPE_': '...   \n",
       "630  D272  [{'QID': 'D272Q09', 'QTYPE': '進階題', 'ATYPE_': ...   \n",
       "731  D288  [{'QID': 'D288Q12', 'QTYPE': '申論', 'ATYPE_': '...   \n",
       "874  D322  [{'QID': 'D322Q07', 'QTYPE': '申論', 'ATYPE_': '...   \n",
       "\n",
       "                                                 DTEXT  \\\n",
       "20   阿拉伯之春（阿拉伯語：الثورات العربية‎）是西方主流媒體所稱的阿拉伯世界的一次...   \n",
       "70   北美自由貿易協定（英語：North American Free Trade Agreemen...   \n",
       "156  聊天機器人並非最近幾年出現的新應用，麻省理工學院（MIT）人工智慧實驗室早在1966年即研發...   \n",
       "284  在自然界中，能源可以採取幾種不同的形式存在：熱，電，輻射，化學能等。許多這些形式可以很容易轉...   \n",
       "324  財團法人伊甸社會福利基金會（英語：Eden Social Welfare Foundatio...   \n",
       "370  根據政府公權力介入的程度，健康照護體系一般可以區分為以下三種不同的體系。\\n社會保險制（台灣...   \n",
       "371  根據政府公權力介入的程度，健康照護體系一般可以區分為以下三種不同的體系。\\n社會保險制（台灣...   \n",
       "395  在流行病學家及醫學研究者繼續探討癌症的相關生活因素的同時，美國醫學會所出版的著名醫學雜誌也於...   \n",
       "449  國慶焰火在9月24號晚間試放3分鐘，為確保施放安全、順利，屏東縣政府表示24號當天屏東河濱公...   \n",
       "502  到了15世紀，聖伯多祿大殿結構日益變舊，亞維農教廷遷回羅馬後，萊昂·巴蒂斯塔·阿伯提和貝爾納...   \n",
       "630  我們現在有好幾種筆可以使用：表現中國書法的特點，用毛筆；適應現代光面的紙張，用鋼筆；為了可以...   \n",
       "731  如果你到埃及旅行，沿著尼羅河前進，你將會看到一座座巍峨的金字塔，矗立在一望無際沙漠中。在蔚藍...   \n",
       "874  國內腸病毒輕症疫情持續上升，另新增1例腸病毒71型併發重症病例。疾病管制署再次呼籲，腸病毒傳...   \n",
       "\n",
       "                                              DTEXT_CN  \\\n",
       "20   阿拉伯之春（阿拉伯语：الثورات العربية‎）是西方主流媒体所称的阿拉伯世界的一次...   \n",
       "70   北美自由贸易协定（英语：North American Free Trade Agreemen...   \n",
       "156  聊天机器人并非最近几年出现的新应用，麻省理工学院（MIT）人工智慧实验室早在1966年即研发...   \n",
       "284  在自然界中，能源可以采取几种不同的形式存在：热，电，辐射，化学能等。许多这些形式可以很容易转...   \n",
       "324  财团法人伊甸社会福利基金会（英语：Eden Social Welfare Foundatio...   \n",
       "370  根据政府公权力介入的程度，健康照护体系一般可以区分为以下三种不同的体系。\\n社会保险制（台湾...   \n",
       "371  根据政府公权力介入的程度，健康照护体系一般可以区分为以下三种不同的体系。\\n社会保险制（台湾...   \n",
       "395  在流行病学家及医学研究者继续探讨癌症的相关生活因素的同时，美国医学会所出版的著名医学杂志也于...   \n",
       "449  国庆焰火在9月24号晚间试放3分钟，为确保施放安全、顺利，屏东县政府表示24号当天屏东河滨公...   \n",
       "502  到了15世纪，圣伯多禄大殿结构日益变旧，亚维农教廷迁回罗马后，莱昂·巴蒂斯塔·阿伯提和贝尔纳...   \n",
       "630  我们现在有好几种笔可以使用：表现中国书法的特点，用毛笔；适应现代光面的纸张，用钢笔；为了可以...   \n",
       "731  如果你到埃及旅行，沿著尼罗河前进，你将会看到一座座巍峨的金字塔，矗立在一望无际沙漠中。在蔚蓝...   \n",
       "874  国内肠病毒轻症疫情持续上升，另新增1例肠病毒71型并发重症病例。疾病管制署再次呼吁，肠病毒传...   \n",
       "\n",
       "                                                 SENTS train_pred train_obs  \n",
       "20   [{'text': '阿拉伯之春（阿拉伯语：الثورات العربية‎）是西方主流媒体...        [9]        []  \n",
       "70   [{'text': '北美自由贸易协定（英语：North American Free Tra...       [11]        []  \n",
       "156  [{'text': '聊天机器人并非最近几年出现的新应用，', 'start': 0, 'e...        [1]        []  \n",
       "284  [{'text': '在自然界中，', 'start': 0, 'end': 6, 'IE'...        [3]        []  \n",
       "324  [{'text': '财团法人伊甸社会福利基金会（英语：Eden Social Welfar...        [4]        []  \n",
       "370  [{'text': '根据政府公权力介入的程度，', 'start': 0, 'end': ...   [12, 25]      [25]  \n",
       "371  [{'text': '根据政府公权力介入的程度，', 'start': 0, 'end': ...   [12, 25]      [12]  \n",
       "395  [{'text': '在流行病学家及医学研究者继续探讨癌症的相关生活因素的同时，', 'st...       [10]        []  \n",
       "449  [{'text': '国庆焰火在9月24号晚间试放3分钟，', 'start': 0, 'e...        [2]        []  \n",
       "502  [{'text': '到了15世纪，', 'start': 0, 'end': 7, 'IE...        [7]        []  \n",
       "630  [{'text': '我们现在有好几种笔可以使用：表现中国书法的特点，', 'start':...       [62]        []  \n",
       "731  [{'text': '如果你到埃及旅行，', 'start': 0, 'end': 9, '...        [9]        []  \n",
       "874  [{'text': '国内肠病毒轻症疫情持续上升，', 'start': 0, 'end':...       [22]        []  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_with_performance[training_data_with_performance['train_pred'] != training_data_with_performance['train_obs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'QID': 'D048Q09',\n",
       "  'QTYPE': '申論',\n",
       "  'ATYPE_': 'Object',\n",
       "  'AMODE_': ['Single-Span-Extraction'],\n",
       "  'QTEXT': '聊天機器人仰賴哪些方法讓回答愈來愈準確?',\n",
       "  'QTEXT_CN': '聊天机器人仰赖哪些方法让回答愈来愈准确?',\n",
       "  'SENTS': [{'text': '聊天机器人仰赖哪些方法让回答愈来愈准确?',\n",
       "    'start': 0,\n",
       "    'end': 20,\n",
       "    'IE': {'NER': [],\n",
       "     'COREF': {},\n",
       "     'RELATION': [],\n",
       "     'TOKEN': [{'word': '聊天', 'char_b': 0, 'char_e': 2, 'pos': 'NN'},\n",
       "      {'word': '机器人', 'char_b': 2, 'char_e': 5, 'pos': 'NN'},\n",
       "      {'word': '仰赖', 'char_b': 5, 'char_e': 7, 'pos': 'VV'},\n",
       "      {'word': '哪些', 'char_b': 7, 'char_e': 9, 'pos': 'DT'},\n",
       "      {'word': '方法', 'char_b': 9, 'char_e': 11, 'pos': 'NN'},\n",
       "      {'word': '让', 'char_b': 11, 'char_e': 12, 'pos': 'VV'},\n",
       "      {'word': '回答', 'char_b': 12, 'char_e': 14, 'pos': 'VV'},\n",
       "      {'word': '愈来愈', 'char_b': 14, 'char_e': 17, 'pos': 'AD'},\n",
       "      {'word': '准确', 'char_b': 17, 'char_e': 19, 'pos': 'VA'},\n",
       "      {'word': '?', 'char_b': 19, 'char_e': 20, 'pos': 'PU'}]}}],\n",
       "  'SHINT_': [],\n",
       "  'ANSWER': [{'ATEXT': '',\n",
       "    'ATEXT_CN': '',\n",
       "    'ATOKEN': [{'text': '', 'text_cn': '', 'start': 0, 'end': 0}]}]}]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_with_performance[training_data_with_performance['train_pred'] != training_data_with_performance['train_obs']]['QUESTIONS'][156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'国内肠病毒轻症疫情持续上升，另新增1例肠病毒71型并发重症病例。疾病管制署再次呼吁，肠病毒传染力强，家长与教托育机构人员不可轻忽，应加强居家环境、教室及游乐设施等的通风、整洁与消毒，并教导学童落实「湿、搓、冲、捧、擦」正确洗手步骤，及生病在家休息等良好卫生观念，以降低病毒于校园或社区中传播的风险。\\n疾管署表示，新增之肠病毒并发重症个案为南部7岁男童，9月1日至2日陆续出现手足口症、食欲下降、呕吐、发烧、腹部疼痛、喉咙痛及咳嗽等症状，9月4日个案因症状持续且出现疑似肌抽跃、疱疹性咽峡炎及对答反应慢等情形，经就医转诊后收治住院，5日由医院采检通报，经检验审查确认感染肠病毒71型并发重症(脑炎)，所幸个案经治疗后症状改善并已出院。\\n疾管署监测资料显示，上周(9月8日至9月14日)国内肠病毒门急诊就诊共计20,585人次，较前一周上升6.5%；近期就诊人次持续上升，疫情处流行高峰期。今(2019)年累计37例肠病毒并发重症病例，以感染肠病毒71型为多(28例)，其他分别感染肠病毒D68型、克沙奇A6型、A10型(各2例)，克沙奇A9型、B5型、伊科病毒11型(各1例)。近四周社区肠病毒检出型别以克沙奇A群为多，肠病毒71型持续活动；今年累计315例肠病毒71型个案，高于2016至2018年同期。\\n疾管署表示，肠病毒感染者在发病前几天，喉咙与粪便就有病毒存在且具传染力，发病后一周内传染力最高，痊愈后肠病毒会随著粪便排出达8到12周之久。提醒民众如感染肠病毒，应在家休息并避免与其他婴幼儿接触；痊愈后仍应注意个人手部卫生，以免将病毒传染给其他幼儿造成交叉感染。如发现家中婴幼儿出现肢体无力麻痺，或有嗜睡、意识不清、活力不佳、手脚无力、肌跃型抽搐(无故惊吓或全身肌肉突然收缩)、持续呕吐与呼吸急促或心跳加快等肠病毒重症前兆病征，请尽速送大医院接受治疗。'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_with_performance.loc[874]['DTEXT_CN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'如果你到埃及旅行，沿著尼罗河前进，你将会看到一座座巍峨的金字塔，矗立在一望无际沙漠中。在蔚蓝的天空下，这些已有好几千年历史的庞然大物，不但显得傲岸不群，更给人一种神秘的感觉。\\n到底金字塔这种古老的建筑，是做什么用的呢？原来它是专为埃及国王所设计的陵墓。古埃及人相信：人死后只要把遗体保存好，就可以在另一个世界得到永生。所以尊贵的国王一旦去世，埃及人会先把他们的遗体做防腐的处理，再用泡过香料的布条层层包裹好，制成「木乃伊」，放进棺木中。然后安置在金字塔内部的墓室里，再启动机关，放下巨石，堵住通道，将整个金字塔封闭起来。这样一来，便可以防止盗墓者的侵入破坏，让遗体永享安宁了。\\n在尼罗河沿岸，大大小小的金字塔遗址，大约有八十多座。其中以位于基沙的三座金字塔，以及在塔前担任守护神的人面狮身像，最为宏伟壮观。这些金字塔都是用大石块堆砌建造的。底部为四方形，四面则为平滑的三角斜面。单是规模最大的古夫王金字塔，面积就有五个足球场大。它总共使用了二百三十多万块的大石头，每块足足有两吨半重。塔高一百四十六公尺，相当于四十层高的摩天大楼。据说古夫王生前动用了十几万名工人，花费了二十年的时间，才完成这座世界最大的金字塔。\\n我们很难想像，远在二、三千年前，没有电力，没有机器的情形下，这样庞大的建筑物究竟是怎么建成的。一般的推测是：聪明的埃及人，利用尼罗河每年雨季上涨的洪流，把采石工从岸山上一斧一整切下来的石材，顺著水流用木筏运送到工地去。再用大量的砖块在金字塔的外侧，建造一条盘旋而上的坡道，这样就可以让成千上万的工人，用绳子、滚木把石块顺著斜坡缓缓的往上拖，一层层的累积，叠成金字塔。\\n几千年后的今天，每年都有许多游客从世界各地涌来，观看这号称「世界奇迹」的建筑物。光芒四射的金字塔，不仅透露出埃及国王的权势和追求永生的心愿，更展现了古埃及人的智慧和建筑技术。'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_with_performance.loc[731]['DTEXT_CN']#[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20 (Pred:[9], Actual:[])\n",
    "\n",
    "Question:「阿拉伯之春」运动中，走上街头的民众的诉求为何? <br>\n",
    "Predicted SP: 只有突尼西亚成为阿拉伯之春中，<br>\n",
    "Actual: None\n",
    "\n",
    "Comment: While the predicted SP is incorrect, I found out that there is supporting evidence in the paragraph. (...要求推翻本国的专制政体的行动)This might be a case of incorrect input.\n",
    "\n",
    "#70 (Pred:[11], Actual:[])\n",
    "\n",
    "Question: 第二次签订的北美贸易协定从签署至生效过了几日? <br>\n",
    "Predicted SP: 美国、墨西哥和加拿大就更新北美自由贸易协定达成一致，<br>\n",
    "Actual: None\n",
    "\n",
    "Comment: Same as #20. (美国、加拿大及墨西哥在1992年8月12日签署了关于三国间全面贸易的协议。...，北美自由贸易协议于1994年1月1日正式生效。)\n",
    "\n",
    "#156 (Pred:[1], Actual:[])\n",
    "\n",
    "Question: 聊天机器人仰赖哪些方法让回答愈来愈准确? <br>\n",
    "Predicted SP: 麻省理工学院（MIT）人工智慧实验室早在1966年即研发出名为「Eliza」的机器人， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Same (聊天机器人的作答准确度要透过程式化的方法改善)\n",
    "\n",
    "#284 (Pred:[3], Actual:[])\n",
    "\n",
    "Question: 不可再生能源的意义是什么？ <br>\n",
    "Predicted SP: 许多这些形式可以很容易转化为另一种的帮助下， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Same (是无法经过短时间内再生的能源，而且它们的消耗速度远远超过它们再生的速度)\n",
    "\n",
    "#324 (Pred:[4], Actual:[])\n",
    "\n",
    "Question: 伊甸基金會成立的宗旨為何? <br>\n",
    "Predicted SP: 因著上帝的呼召及一颗爱身心障碍者的同理心，<br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: No SP in the paragraph. But I think SP is pretty close to being a supporting evidence. This \n",
    "must be a borderline case.\n",
    "\n",
    "#370 (Pred:[12,25], Actual:[25])\n",
    "\n",
    "Question: 三大健康照护体系保险制度中，政府涉入程度低的是哪一种？<br>\n",
    "Predicted SP: 公医制（政府介入最多）：以英国为代表。 AND 自由市场（政府一般不介入）：以2013年前的美国为代表。<br>\n",
    "Actual: 公医制（政府介入最多）：以英国为代表。<br>\n",
    "\n",
    "Comment: I think this is a very reasonable mismatch. As two supporting evidences are very similar\n",
    "syntax-wise but drastically different in meaning.\n",
    "\n",
    "#371 (Pred:[12,25], Actual:[12])\n",
    "\n",
    "Question: 三大健康照護體系保險制度中，政府涉入程度高的是哪一種？ <br>\n",
    "Predicted SP: 公医制（政府介入最多）：以英国为代表。 AND 自由市场（政府一般不介入）：以2013年前的美国为代表。<br>\n",
    "Actual: 公医制（政府介入最多）：以英国为代表。<br>\n",
    "\n",
    "Comment: Same as #370\n",
    "\n",
    "#395 (Pred:[10], Actual:[])\n",
    "\n",
    "Question: 熬夜是否能减低得到癌症的风险? <br>\n",
    "Predicted SP: 皆强烈建议减少或避免动物性食品摄取， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Another potential case of incorrect input. In the paragraph I found this sentence (所以防癌守则：...，注重睡眠品质)\n",
    "\n",
    "#449 (Pred:[2], Actual:[])\n",
    "\n",
    "Question: 高屏地区国庆烟火试放管制时间是从晚上几点开始？ <br>\n",
    "Predicted SP: 屏东县政府表示24号当天屏东河滨公园将管制不开放， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Another similar case. This time I strongly believe this is an incorrect input. \n",
    "当晚7时并会进行全面清场 <- This is sufficient to be a supporting evidence\n",
    "\n",
    "#502 (Pred:[7], Actual:[])\n",
    "\n",
    "Question: 为何圣伯多禄大殿只能重建不能整修就好? <br>\n",
    "Predicted SP: 教宗犹利二世决定重建圣伯多禄大殿 <br>\n",
    "Actual: None \n",
    "\n",
    "Comment: Another similar case. (无疑再改动有机会让建筑倒塌)\n",
    "\n",
    "#630 (Pred:[62], Actual:[])\n",
    "\n",
    "Question: 毛笔、铅笔、钢笔，这三种笔中哪个笔尖的硬度高？ <br>\n",
    "Predicted SP: 更进一步看：我们无论使用那一种笔，<br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Again, I think this counts as a supporting evidence (钢笔的笔尖用金属制成，弹性大，硬度高)\n",
    "\n",
    "#731 (Pred:[9], Actual:[])\n",
    "\n",
    "Question: 为什么古埃及人要把死人做成木乃伊? <br>\n",
    "Predicted SP: 是做什么用的呢？ <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: I think this counts (古埃及人相信：人死后只要把遗体保存好，就可以在另一个世界得到永生。)\n",
    "\n",
    "#874 (Pred:[22], Actual:[])\n",
    "\n",
    "Question: 要如何降低肠病毒的传播风险？\n",
    "Predicted SP: 今(2019)年累计37例肠病毒并发重症病例，\n",
    "Actual: None\n",
    "\n",
    "Comment: No doubt, these are supporting evidences (应加强居家环境、教室及游乐设施等的通风、整洁与消毒，并教导学童落实「湿、搓、冲、捧、擦」正确洗手步骤，及生病在家休息等良好卫生观念，)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
